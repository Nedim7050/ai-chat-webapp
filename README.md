# AI Chat Webapp

Application complÃ¨te de chatbot IA avec deux variantes de dÃ©ploiement:
1. **Full-stack**: Backend FastAPI + Frontend React
2. **Streamlit-only**: Application Streamlit standalone

## ğŸš€ DÃ©marrage rapide

### Variante A: Full-stack (FastAPI + React)

#### Backend

```powershell
# Windows PowerShell
cd backend
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r app/requirements.txt
uvicorn app.main:app --reload --port 8000
```

```bash
# Linux/Mac
cd backend
python -m venv .venv
source .venv/bin/activate
pip install -r app/requirements.txt
uvicorn app.main:app --reload --port 8000
```

Le backend sera accessible sur `http://localhost:8000`

#### Frontend

```bash
cd frontend
npm install
npm run dev
```

Le frontend sera accessible sur `http://localhost:5173`

### Variante B: Streamlit-only

```powershell
# Windows PowerShell
cd streamlit_app
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt
streamlit run app.py
```

```bash
# Linux/Mac
cd streamlit_app
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
streamlit run app.py
```

L'application sera accessible sur `http://localhost:8501`

## ğŸ“ Structure du projet

```
ai-chat-webapp/
â”œâ”€â”€ backend/                 # Backend FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py         # Application FastAPI principale
â”‚   â”‚   â”œâ”€â”€ model.py        # Wrapper pour le modÃ¨le IA
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ frontend/               # Frontend React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Composant principal React
â”‚   â”‚   â”œâ”€â”€ App.css         # Styles
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ streamlit_app/          # Application Streamlit
â”‚   â”œâ”€â”€ app.py              # Application Streamlit complÃ¨te
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ models/                 # Instructions pour les modÃ¨les
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ README.md               # Ce fichier
â””â”€â”€ LICENSE
```

## ğŸ”§ Configuration

### Backend

Le backend utilise par dÃ©faut le modÃ¨le `microsoft/DialoGPT-small`. Pour changer de modÃ¨le, modifiez `backend/app/model.py`:

```python
chat_model = ChatModel(model_name="votre-modele")
```

### Frontend

Pour changer l'URL de l'API backend, crÃ©ez un fichier `.env` dans `frontend/`:

```
VITE_API_URL=http://localhost:8000
```

## ğŸ“¦ DÃ©ploiement

### Backend (FastAPI)

#### Render / Heroku

1. CrÃ©ez un compte sur [Render](https://render.com) ou [Heroku](https://heroku.com)
2. Connectez votre repo GitHub
3. CrÃ©ez un nouveau service web
4. Configurez:
   - **Build Command**: `pip install -r backend/app/requirements.txt`
   - **Start Command**: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`
   - **Working Directory**: `backend`

#### Railway

1. Connectez votre repo GitHub Ã  [Railway](https://railway.app)
2. SÃ©lectionnez le dossier `backend`
3. Railway dÃ©tectera automatiquement FastAPI et installera les dÃ©pendances

### Frontend (React)

#### Vercel

1. Connectez votre repo GitHub Ã  [Vercel](https://vercel.com)
2. Configurez:
   - **Framework Preset**: Vite
   - **Root Directory**: `frontend`
   - **Build Command**: `npm run build`
   - **Output Directory**: `dist`
3. Ajoutez la variable d'environnement `VITE_API_URL` avec l'URL de votre backend dÃ©ployÃ©

#### Netlify

1. Connectez votre repo GitHub Ã  [Netlify](https://netlify.com)
2. Configurez:
   - **Base directory**: `frontend`
   - **Build command**: `npm run build`
   - **Publish directory**: `frontend/dist`
3. Ajoutez la variable d'environnement `VITE_API_URL`

### Streamlit App

#### Streamlit Cloud

1. Poussez votre code sur GitHub
2. Allez sur [share.streamlit.io](https://share.streamlit.io)
3. Connectez votre compte GitHub
4. CrÃ©ez une nouvelle app:
   - **Repository**: Votre repo
   - **Branch**: `main` (ou `master`)
   - **Main file path**: `streamlit_app/app.py`
5. Cliquez sur "Deploy"

L'application sera accessible sur `https://votre-app.streamlit.app`

## ğŸ§ª Tests

### Tester le backend

```bash
# Health check
curl http://localhost:8000/health

# Chat endpoint
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Bonjour!", "history": []}'
```

### Tester le frontend

Ouvrez `http://localhost:5173` dans votre navigateur et testez l'interface de chat.

### Tester Streamlit

Ouvrez `http://localhost:8501` dans votre navigateur et testez l'application.

## ğŸ“š Documentation API

Une fois le backend lancÃ©, accÃ©dez Ã :
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ”’ SÃ©curitÃ© et performances

### Recommandations

1. **Rate limiting**: Ajoutez un middleware de rate limiting pour Ã©viter les abus
2. **ModÃ¨les lÃ©gers**: Utilisez des modÃ¨les petits pour rÃ©duire l'utilisation mÃ©moire
3. **API Hugging Face**: Pour la production, considÃ©rez l'utilisation de l'API Hugging Face Inference au lieu de charger le modÃ¨le localement
4. **CORS**: Configurez correctement les origines CORS pour la production

### Exemple de rate limiting (optionnel)

Ajoutez dans `backend/app/main.py`:

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/chat")
@limiter.limit("10/minute")
async def chat(request: Request, chat_request: ChatRequest):
    # ...
```

## ğŸ› DÃ©pannage

### Le modÃ¨le ne se charge pas

- VÃ©rifiez votre connexion internet (tÃ©lÃ©chargement initial)
- Assurez-vous d'avoir suffisamment d'espace disque (2-3 GB)
- VÃ©rifiez les logs pour plus de dÃ©tails

### Erreur de mÃ©moire

- Utilisez un modÃ¨le plus petit
- RÃ©duisez la taille du batch
- Utilisez l'API Hugging Face Inference

### CORS errors

- VÃ©rifiez que l'URL du frontend est dans `allow_origins` du backend
- Pour la production, remplacez `localhost` par votre domaine

## ğŸ“ Licence

Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ¤ Contribution

Les contributions sont les bienvenues! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“§ Support

Pour toute question ou problÃ¨me, ouvrez une issue sur GitHub.

