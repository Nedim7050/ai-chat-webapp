# Streamlit App

Application Streamlit standalone pour le chatbot IA, d√©ployable sur Streamlit Cloud sans Docker.

## Installation locale

### 1. Cr√©er un environnement virtuel

```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

Sur Linux/Mac:
```bash
python -m venv .venv
source .venv/bin/activate
```

### 2. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 3. Lancer l'application

```bash
streamlit run app.py
```

L'application sera accessible sur `http://localhost:8501`

## D√©ploiement sur Streamlit Cloud

### M√©thode 1: Via GitHub

1. **Pousser votre code sur GitHub**
   - Cr√©ez un repo GitHub
   - Poussez le dossier `streamlit_app/` √† la racine ou dans un sous-dossier

2. **Connecter √† Streamlit Cloud**
   - Allez sur [share.streamlit.io](https://share.streamlit.io)
   - Connectez votre compte GitHub
   - Cliquez sur "New app"
   - S√©lectionnez votre repo et la branche
   - **Chemin principal:** `streamlit_app/app.py` (ou `app.py` si √† la racine)
   - Cliquez sur "Deploy"

3. **Attendre le d√©ploiement**
   - Streamlit Cloud installera automatiquement les d√©pendances depuis `requirements.txt`
   - Le premier d√©ploiement peut prendre quelques minutes (t√©l√©chargement du mod√®le)

### M√©thode 2: Via Streamlit CLI

```bash
streamlit login
streamlit deploy streamlit_app/app.py
```

## Fonctionnalit√©s

- üí¨ Interface de chat intuitive
- üóëÔ∏è Bouton pour effacer la conversation
- üì• T√©l√©chargement de la conversation en JSON
- üîÑ Gestion de l'historique de conversation
- ‚ö° Mod√®le charg√© en cache pour de meilleures performances

## Structure du fichier

Le fichier `app.py` contient:
- Chargement du mod√®le (avec cache Streamlit)
- Interface utilisateur compl√®te
- Gestion de l'historique de conversation
- Export de conversation

## Notes

- Le mod√®le se charge au premier lancement (peut prendre du temps)
- Streamlit Cloud utilise des ressources limit√©es, privil√©giez des mod√®les l√©gers
- Pour de meilleures performances, consid√©rez l'utilisation de l'API Hugging Face Inference

## D√©pannage

**Erreur de m√©moire:**
- Utilisez un mod√®le plus petit ou l'API Hugging Face Inference
- R√©duisez la taille du batch dans le code

**Mod√®le ne se charge pas:**
- V√©rifiez votre connexion internet (t√©l√©chargement initial)
- V√©rifiez que le mod√®le existe sur Hugging Face
- Consultez les logs Streamlit Cloud pour plus de d√©tails

